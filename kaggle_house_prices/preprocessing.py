# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/01_preprocessing.ipynb (unless otherwise specified).

__all__ = ['dir_raw_data', 'compressed_data_file', 'train_path', 'test_path', 'dep_var', 'show_dep_var', 'cont_names',
           'show_na_share', 'cat_names', 'do_sample', 'get_split', 'val_col', 'deal_with_continuous_nans',
           'inspect_category_mappings', 'model_data_path', 'clean_data_path', 'clean_test_data_path',
           'clean_data_path_feather', 'clean_test_data_path_feather']

# Cell
from zipfile import ZipFile
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np
from typing import List
from fastai2.tabular.all import *

from .utils import *

# Cell
dir_raw_data = Path("../data/raw")
# competition = "house-prices-advanced-regression-techniques"
compressed_data_file = dir_raw_data/f"{competition}.zip"

# Cell
train_path = dir_raw_data/"train.csv"
test_path = dir_raw_data/"test.csv"

# Cell
dep_var = "SalePrice"

# Cell
def show_dep_var(df:pd.DataFrame, dep_var:str, bins:int=50):
    "Shows the `dep_var` distribution, linear and logarithmic, side by side."
    bins = 50

    fig, axs = plt.subplots(ncols=2, figsize=(14,4))
    ax = axs[0]
    ax.hist(df[dep_var].values, bins=bins)
    ax.set_title(f"{dep_var}")
    ax = axs[1]
    ax.hist(np.log(df[dep_var].values), bins=bins)
    ax.set_title(f"log({dep_var})")
    plt.show()

# Cell
cont_names = ['LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF2', 'BsmtUnfSF',
              'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea',
              'WoodDeckSF', 'OpenPorchSF', 'LotFrontage', 'BsmtFinSF1', 'LowQualFinSF',]

# Cell
def show_na_share(df:pd.DataFrame, cols:List[str]):
    "Prints the share of NaN values by column"
    for col in cols:
        if df[col].hasnans:
            print(f"{col}: {df[col].isna().sum()/len(df)*100:.2f} %")

# Cell
cat_names = ['Id', 'MSSubClass', 'MSZoning', 'Street',
       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',
       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',
       'HouseStyle', 'OverallQual', 'OverallCond',
       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',
       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',
       'BsmtCond', 'BsmtExposure', 'BsmtFinType1',
       'BsmtFinType2', 'Heating',
       'HeatingQC', 'CentralAir', 'Electrical',
       'BsmtFullBath', 'BsmtHalfBath', 'FullBath',
       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',
       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',
       'GarageFinish', 'GarageCars', 'GarageQual',
       'GarageCond', 'PavedDrive',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',
       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'SaleType',
       'SaleCondition']

# Cell
def do_sample(df:pd.DataFrame, small_sample:bool, n:int=100) -> pd.DataFrame:
    "Generates samples from `df`."
    if small_sample:
        _df = df.sample(n=n)
    else:
        _df = df.copy(deep=True)
    return _df

# Cell
val_col = "is_valid"

def get_split(df:pd.DataFrame, valid_pct:float=.2, val_col="is_valid") -> pd.DataFrame:
    "Splitting the data frame into train and validation set, creating a new `val_col` column"
    valid_idx = np.arange(int((1-valid_pct)*len(df)), len(df))
    train_idx = np.setdiff1d(np.arange(len(df)), valid_idx)
    df[val_col] = False
    df.iloc[valid_idx, df.columns.get_loc(val_col)] = True
    return df

# Cell
def deal_with_continuous_nans(df_ref:pd.DataFrame, df_new, cont_names:list, cont_fill_vals:dict):
    "Fills nans in columns of `df_new` if they are unexpected based on `df_ref`"
    for col in cont_names:
        reference_set_has_nan = pd.isnull(df_ref[col]).any()
        new_set_has_nan = pd.isnull(df_new[col]).any()

        if new_set_has_nan and not reference_set_has_nan:
            df_new[col].fillna(cont_fill_vals[col], inplace=True)
    return df_new

# Cell
def inspect_category_mappings(cat_names:List[str], df:pd.DataFrame, splits:ColSplitter,
                              to:TabularPandas, n_max:int=None):
    "Shows unique original and transformed discrete values side by side for sanity checks"
    for i, col in enumerate(cat_names):
        print(f"\nColumn: {col}")
        _df = (pd.DataFrame({"original-train": df.iloc[splits[0]][col], "categorified-train": to.train.xs[col]})
               .drop_duplicates()
               .sort_values("categorified-train"))
        display_all(_df.head())
        _df = (pd.DataFrame({"original-valid": df.iloc[splits[1]][col], "categorified-valid": to.valid.xs[col]})
               .drop_duplicates()
               .sort_values("categorified-valid"))
        display_all(_df.head())

        if n_max is not None and i+1 == n_max:
            break

# Cell
model_data_path = "model_data.pckl"

# Cell
clean_data_path = dir_raw_data.parent/"train_clean.csv"
clean_test_data_path = dir_raw_data.parent/"test_clean.csv"
clean_data_path_feather = dir_raw_data.parent/"train_clean.feather"
clean_test_data_path_feather = dir_raw_data.parent/"test_clean.feather"