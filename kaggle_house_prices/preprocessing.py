# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/01_preprocessing.ipynb (unless otherwise specified).

__all__ = ['dir_raw_data', 'compressed_data_file', 'train_path', 'test_path', 'dep_var', 'show_dep_var', 'cont_names',
           'show_na_share', 'cat_names', 'do_sample', 'get_split', 'val_col', 'deal_with_continuous_nans',
           'inspect_category_mappings', 'model_data_path', 'clean_data_path', 'clean_test_data_path',
           'clean_data_path_feather', 'clean_test_data_path_feather']

# Cell
from zipfile import ZipFile
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from typing import List
from fastai2.tabular.all import *

from .utils import *

# Cell
dir_raw_data = Path("../data/raw")
# competition = "house-prices-advanced-regression-techniques"
compressed_data_file = dir_raw_data/f"{competition}.zip"

# Cell
train_path = dir_raw_data/"train.csv"
test_path = dir_raw_data/"test.csv"

# Cell
dep_var = "SalePrice"

# Cell
def show_dep_var(df:pd.DataFrame, dep_var:str, bins:int=50):
    "Shows the `dep_var` distribution, linear and logarithmic, side by side."
    bins = 50

    fig, axs = plt.subplots(ncols=2, figsize=(14,4))
    ax = axs[0]
    ax.hist(df[dep_var].values, bins=bins)
    ax.set_title(f"{dep_var}")
    ax = axs[1]
    ax.hist(np.log(df[dep_var].values), bins=bins)
    ax.set_title(f"log({dep_var})")
    plt.show()

# Cell
cont_names = ['LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF2', 'BsmtUnfSF',
              'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea',
              'WoodDeckSF', 'OpenPorchSF', 'LotFrontage', 'BsmtFinSF1', 'LowQualFinSF',]

# Cell
def show_na_share(df:pd.DataFrame, cols:List[str]):
    "Prints the share of NaN values by column"
    for col in cols:
        if df[col].hasnans:
            print(f"{col}: {df[col].isna().sum()/len(df)*100:.2f} %")

# Cell
cat_names = ['Id', 'MSSubClass', 'MSZoning', 'Street',
       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',
       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',
       'HouseStyle', 'OverallQual', 'OverallCond',
       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',
       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',
       'BsmtCond', 'BsmtExposure', 'BsmtFinType1',
       'BsmtFinType2', 'Heating',
       'HeatingQC', 'CentralAir', 'Electrical',
       'BsmtFullBath', 'BsmtHalfBath', 'FullBath',
       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',
       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',
       'GarageFinish', 'GarageCars', 'GarageQual',
       'GarageCond', 'PavedDrive',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',
       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'SaleType',
       'SaleCondition']

# Cell
def do_sample(df:pd.DataFrame, small_sample:bool, n:int=100) -> pd.DataFrame:
    "Generates samples from `df`."
    if small_sample:
        _df = df.sample(n=n)
    else:
        _df = df.copy(deep=True)
    return _df

# Cell
val_col = "is_valid"

def get_split(df:pd.DataFrame, valid_pct:float=.2, val_col="is_valid") -> pd.DataFrame:
    "Splitting the data frame into train and validation set, creating a new `val_col` column"
    valid_idx = np.arange(int((1-valid_pct)*len(df)), len(df))
    train_idx = np.setdiff1d(np.arange(len(df)), valid_idx)
    df[val_col] = False
    df.iloc[valid_idx, df.columns.get_loc(val_col)] = True
    return df

# Cell
def deal_with_continuous_nans(df_ref:pd.DataFrame, df_new, cont_names:list, cont_fill_vals:dict):
    "Fills nans in columns of `df_new` if they are unexpected based on `df_ref`"
    for col in cont_names:
        reference_set_has_nan = pd.isnull(df_ref[col]).any()
        new_set_has_nan = pd.isnull(df_new[col]).any()

        if new_set_has_nan and not reference_set_has_nan:
            df_new[col].fillna(cont_fill_vals[col], inplace=True)
    return df_new

# Cell
def inspect_category_mappings(cat_names:List[str], df:pd.DataFrame, splits:ColSplitter,
                              to:TabularPandas, n_max:int=None):
    "Shows unique original and transformed discrete values side by side for sanity checks"
    for i, col in enumerate(cat_names):
        print(f"\nColumn: {col}")
        _df = (pd.DataFrame({"original-train": df.iloc[splits[0]][col], "categorified-train": to.train.xs[col]})
               .drop_duplicates()
               .sort_values("categorified-train"))
        display_all(_df.head())
        _df = (pd.DataFrame({"original-valid": df.iloc[splits[1]][col], "categorified-valid": to.valid.xs[col]})
               .drop_duplicates()
               .sort_values("categorified-valid"))
        display_all(_df.head())

        if n_max is not None and i+1 == n_max:
            break

# Cell
model_data_path = "model_data.pckl"

# Cell
clean_data_path = dir_raw_data.parent/"train_clean.csv"
clean_test_data_path = dir_raw_data.parent/"test_clean.csv"
clean_data_path_feather = dir_raw_data.parent/"train_clean.feather"
clean_test_data_path_feather = dir_raw_data.parent/"test_clean.feather"